{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"baseModel_simplified.ipynb","provenance":[],"collapsed_sections":[]},"interpreter":{"hash":"3bf6701e02832dd2a5ff2db11815ba5e3181d882c9793ad793cd6c8a8d13a17d"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wrA_BHth0-RR","executionInfo":{"status":"ok","timestamp":1629121417187,"user_tz":-540,"elapsed":18977,"user":{"displayName":"‍최인열[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8BUm3PMjTAMzbJ-BDYlLb1QoDILXeYHWvRCb8zA=s64","userId":"15703589860586239529"}},"outputId":"5d933955-903e-4c28-af10-4820c2fa190f"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KCdJVKyX2vYo"},"source":["from google.colab.patches import cv2_imshow # cv2_imshow(img)\n","import cv2 as cv\n","import urllib.request\n","import numpy as np\n","import time\n","import tensorflow as tf\n","\n","# for file path\n","import natsort\n","import platform\n","import glob\n","import os\n","\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","mpl.rcParams['figure.figsize'] = (12,12)\n","mpl.rcParams['axes.grid'] = False\n","import PIL.Image\n","import matplotlib.image as img\n","import IPython.display as display"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aEhXKMY_Y61t"},"source":["def model_layers(layer_names): # 전역 변수, StyleContentModel에 이용\n","    \"\"\" 중간층의 출력값을 배열로 반환하는 < > 모델을 만듭니다.\"\"\"\n","    # 이미지넷 데이터셋에 사전학습된 < > 모델을 불러옵니다\n","    # ✅ 모델 선택 가능  tf.keras.applications 문서 참고\n","    model = tf.keras.applications.VGG19(include_top=False, weights='imagenet')\n","    model.trainable = False    \n","    outputs = [model.get_layer(name).output for name in layer_names]\n","    model = tf.keras.Model([model.input], outputs, verbose=2)\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sz3mmXZYNFXZ"},"source":["def load_img(path_to_img): # main, 전역변수\n","  max_dim = 512\n","  img = tf.io.read_file(path_to_img)\n","  img = tf.image.decode_image(img, channels=3)\n","  img = tf.image.convert_image_dtype(img, tf.float32)\n","\n","  shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n","  long_dim = max(shape)\n","  scale = max_dim / long_dim\n","\n","  new_shape = tf.cast(shape * scale, tf.int32)\n","\n","  img = tf.image.resize(img, new_shape)\n","  img = img[tf.newaxis, :]\n","  return img, new_shape   # 사진 크기에 따른 자동화 문제 해결"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"emo1iVqImnJM"},"source":["def gram_matrix(input_tensor): # StyleContentModel\n","    result = tf.linalg.einsum('bijc,bijd->bcd', input_tensor, input_tensor)\n","    input_shape = tf.shape(input_tensor)\n","    num_locations = tf.cast(input_shape[1]*input_shape[2], tf.float32)\n","    return result/(num_locations)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VUfWCFwkOKLO"},"source":["class StyleContentModel(tf.keras.models.Model): # 전역변수 extractor\n","  def __init__(self, style_layers, content_layers):\n","    super(StyleContentModel, self).__init__()\n","    self.model =  model_layers(style_layers + content_layers)\n","    self.style_layers = style_layers\n","    self.content_layers = content_layers\n","    self.num_style_layers = len(style_layers)\n","    self.model.trainable = False\n","\n","  def call(self, inputs):\n","    \"[0,1] 사이의 실수 값을 입력으로 받습니다\"\n","    inputs = inputs*255.0\n","    # ✅ 모델 바꿀 시 변경 필요\n","    preprocessed_input = tf.keras.applications.vgg19.preprocess_input(inputs)\n","    #\n","    outputs = self.model(preprocessed_input)\n","    style_outputs, content_outputs = (outputs[:self.num_style_layers], \n","                                      outputs[self.num_style_layers:])\n","\n","    style_outputs = [gram_matrix(style_output)\n","                     for style_output in style_outputs]\n","\n","    content_dict = {content_name:value \n","                    for content_name, value \n","                    in zip(self.content_layers, content_outputs)}\n","\n","    style_dict = {style_name:value\n","                  for style_name, value\n","                  in zip(self.style_layers, style_outputs)}\n","    \n","    return {'content':content_dict, 'style':style_dict}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iN3LzPrEZ5OT"},"source":["def clip_0_1(image):  # train_step\n","    return tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2zA_zwCVaNCt"},"source":["def style_content_loss(outputs):  # train_step\n","    style_targets = extractor(style_image)['style']\n","    content_targets = extractor(content_image)['content']\n","    # ✅ hyper parameter\n","    style_weight=1e-2\n","    content_weight=1e4\n","    #\n","    num_content_layers = len(content_layers)\n","    num_style_layers = len(style_layers)\n","    \n","    style_outputs = outputs['style']\n","    content_outputs = outputs['content']\n","    style_loss = tf.add_n([tf.reduce_mean((style_outputs[name]-style_targets[name])**2) \n","                        for name in style_outputs.keys()])\n","    style_loss *= style_weight / num_style_layers\n","\n","    content_loss = tf.add_n([tf.reduce_mean((content_outputs[name]-content_targets[name])**2) \n","                            for name in content_outputs.keys()])\n","    content_loss *= content_weight / num_content_layers\n","    loss = style_loss + content_loss\n","    return loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2X-u4t7eZ6px"},"source":["def train_step(image):  # get_transformed_img\n","    with tf.GradientTape() as tape:\n","        outputs = extractor(image)\n","        loss = style_content_loss(outputs)\n","    # ✅ optimizer 선택 가능\n","    opt = tf.optimizers.Adam(learning_rate=0.02, beta_1=0.99, epsilon=1e-1)\n","    grad = tape.gradient(loss, image)\n","    opt.apply_gradients([(grad, image)])\n","    image.assign(clip_0_1(image))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ug6z7Am03DTS"},"source":["def tensor_to_image(tensor): # get_transformed_img\n","  tensor = tensor*255\n","  tensor = np.array(tensor, dtype=np.uint8)\n","  if np.ndim(tensor)>3:\n","    assert tensor.shape[0] == 1\n","    tensor = tensor[0]\n","  return PIL.Image.fromarray(tensor)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hGurczy81Gjr"},"source":["def get_transformed_img(content_image): # main\n","    image = tf.Variable(content_image)\n","\n","    # ✅ hyper parameter\n","    epochs = 20\n","    steps_per_epoch = 3\n","    step = 0\n","\n","    for n in range(epochs):\n","        for m in range(steps_per_epoch):\n","            step += 1\n","            train_step(image)\n","            print(\".\", end='')\n","        # display.clear_output(wait=True)\n","        # display.display(tensor_to_image(image)\n","        # print(\"훈련 스텝: {}\".format(step)) \n","        \n","    img_transformed = np.array(tensor_to_image(image))\n","    return img_transformed"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5qYzPNru9W3K"},"source":["# 전역 변수\n","# ✅ 모델 바꿀 시 변경 필요\n","content_layers = ['block5_conv2']  # style_content_loss, 전역변수  extractor\n","style_layers = ['block1_conv1',\n","                'block2_conv1',\n","                'block3_conv1', \n","                'block4_conv1', \n","                'block5_conv1']     # style_content_loss, 전역변수 extractor"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":161},"id":"DlEMN_5q2g5M","executionInfo":{"elapsed":243,"status":"ok","timestamp":1628932667548,"user":{"displayName":"‍최인열[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8BUm3PMjTAMzbJ-BDYlLb1QoDILXeYHWvRCb8zA=s64","userId":"15703589860586239529"},"user_tz":-540},"outputId":"8ed44212-6ffb-4ee8-94a8-46a42090ddbf"},"source":[" # 작동하는지 확인하는 코드\n","\n"," \"\"\"\n","  content_location = \"/content/drive/Shareddrives/SWTube/프로젝트/044. 2021 소융튜브 특성화 프로젝트/데이터 팀/mount_drive/Darkest-Cave/Data/Content_Images/goblin/Layer 1_sprite_01.png\"\n","  \n","  style_image, style_shape = load_img(style_location)\n","  content_image, content_shpae = load_img(content_location)\n","  plt.figure(figsize=(8,8))\n","\n","  plt.subplot(221)\n","  plt.imshow(style_image[0])\n","  plt.axis('off')\n","\n","  plt.subplot(222)\n","  plt.imshow(content_image[0])\n","  plt.axis('off')\n","\n","  plt.show()\n","\n","  origin_image = cv.imread(content_location, cv.IMREAD_UNCHANGED)\n","  origin_image_shape = origin_image.shape\n","\n","  # style transfer\n","  content_image, content_shape = load_img(content_location) \n","  img_transformed = get_transformed_img(content_image)\n","  b, g, r = cv.split(img_transformed)\n","  img_transformed = cv.merge([r,g,b])\n","\n","  # model이 반환한 이미지와 사이즈 동일하게 origin image 변환(자동화 완료)\n","  shape = content_shape.numpy()\n","  x, y = shape\n","  origin_image_resized = cv.resize(origin_image, dsize=(y,x))\n","\n","  # alpha channel 추가\n","  final = cv.cvtColor(img_transformed, cv.COLOR_RGB2RGBA)\n","  final[:, :, 3] = origin_image_resized[:,:,3]\n","\n","  # final image 사이즈를 original image 사이즈로 변환\n","  x, y = origin_image_shape[0], origin_image_shape[1]\n","  final = cv.resize(final, dsize=(y,x))\n","\n","  cv2_imshow(final)\n","\"\"\""],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\n content_location = \"/content/drive/Shareddrives/SWTube/프로젝트/044. 2021 소융튜브 특성화 프로젝트/데이터 팀/mount_drive/Darkest-Cave/Data/Content_Images/goblin/Layer 1_sprite_01.png\"\\n \\n style_image, style_shape = load_img(style_location)\\n content_image, content_shpae = load_img(content_location)\\n plt.figure(figsize=(8,8))\\n\\n plt.subplot(221)\\n plt.imshow(style_image[0])\\n plt.axis(\\'off\\')\\n\\n plt.subplot(222)\\n plt.imshow(content_image[0])\\n plt.axis(\\'off\\')\\n\\n plt.show()\\n\\n origin_image = cv.imread(content_location, cv.IMREAD_UNCHANGED)\\n origin_image_shape = origin_image.shape\\n\\n # style transfer\\n content_image, content_shape = load_img(content_location) \\n img_transformed = get_transformed_img(content_image)\\n b, g, r = cv.split(img_transformed)\\n img_transformed = cv.merge([r,g,b])\\n\\n # model이 반환한 이미지와 사이즈 동일하게 origin image 변환(자동화 완료)\\n shape = content_shape.numpy()\\n x, y = shape\\n origin_image_resized = cv.resize(origin_image, dsize=(y,x))\\n\\n # alpha channel 추가\\n final = cv.cvtColor(img_transformed, cv.COLOR_RGB2RGBA)\\n final[:, :, 3] = origin_image_resized[:,:,3]\\n\\n # final image 사이즈를 original image 사이즈로 변환\\n x, y = origin_image_shape[0], origin_image_shape[1]\\n final = cv.resize(final, dsize=(y,x))\\n\\n cv2_imshow(final)\\n'"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"43UGG8TzctLh"},"source":["# 경로 설정 명세서\n","platform_path = platform.platform()\n","\n","IsColab = \"bionic\" in platform_path\n","if IsColab:\n","  style_location = \"/content/drive/Shareddrives/SWTube/프로젝트/044. 2021 소융튜브 특성화 프로젝트/데이터 팀/mount_drive/Darkest-Cave/Data/Style_Images/*\"\n","  content_location = \"/content/drive/Shareddrives/SWTube/프로젝트/044. 2021 소융튜브 특성화 프로젝트/데이터 팀/mount_drive/Darkest-Cave/Data/Content_Images/*\"\n","  styled_location = \"/content/drive/Shareddrives/SWTube/프로젝트/044. 2021 소융튜브 특성화 프로젝트/데이터 팀/mount_drive/Darkest-Cave/Data/Styled_Images/\"\n","else:\n","  style_location = 'Style_Images/*'\n","  content_location = \"Content_Images/*\"\n","  styled_location = \"Styled_Images/\"\n","\n","# 해당 폴더 내에 존재하는 모든 폴더 리스트 불러오기\n","style_folder_list = glob.glob(style_location)\n","style_images_list = glob.glob(style_folder_list[0] + \"/*\")\n","\n","# Style_location\n","# Style_Images/TEXTURE/*.jpg or png\n","\n","# style_images_list, style_image 활용\n","# style_image = style_images_list[index]\n","\n","# Content_location\n","  # Content_Images/ASSET_NAME/*.png\n","content_folder_list = glob.glob(content_location) # Content_Images/ASSET_NAME\n","\n","# content_images_list, content_image 활용\n","# content_images_list = glob.glob(content_folder_list[index] + \"/*\")\n","# content_image = style_images_list[index]\n","\n","# Styled_location\n","  # Styled_Images/ASSET_NAME/*.png\n","# asset_name = os.path.split(content_folder_list[index])\n","\n","# 폴더 생성\n","def createFolder(directory):\n","    try:\n","        if not os.path.exists(directory):\n","            os.makedirs(directory)\n","    except OSError:\n","        print ('Error: Creating directory. ' +  directory)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c04yAK-0F54t"},"source":["# 구글 코랩에서 장시간 사용하기\n","\n","### F12 개발자 모드 후 Console에 입력\n","\n","```javascript\n","function ClickConnect() {\n","    var buttons = document.querySelectorAll(\"colab-dialog.yes-no-dialog paper-button#cancel\"); \n","    buttons.forEach(function(btn) { \n","        btn.click(); \n","    }); \n","    console.log(\"1분마다 자동 재연결\"); \n","    document.querySelector(\"colab-toolbar-button#connect\").click(); \n","} \n","setInterval(ClickConnect,1000*60);\n","```\n","\n","```javascript\n","function CleanCurrentOutput(){ \n","    var btn = document.querySelector(\".output-icon.clear_outputs_enabled.output-icon-selected[title$='현재 실행 중...'] iron-icon[command=clear-focused-or-selected-outputs]\"); \n","    if(btn) { console.log(\"30분마다 출력 지우기\");\n","     btn.click(); \n","    } \n","} \n","setInterval(CleanCurrentOutput,1000*60*30);\n","```"]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","output_embedded_package_id":"18Bi5Hx9JjwdSbIF2WX0yFmrpX-xy7EmF"},"id":"_3MqyyMCHl3A","executionInfo":{"elapsed":0,"status":"error","timestamp":1629114831092,"user":{"displayName":"‍최인열[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8BUm3PMjTAMzbJ-BDYlLb1QoDILXeYHWvRCb8zA=s64","userId":"15703589860586239529"},"user_tz":-540},"outputId":"5de86916-8545-4ec9-a183-c5630d43ddf9"},"source":["## main code\n","import time\n","start = time.time()\n","\n","# 스타일 폴더 리스트\n","for SF_index, SF_value in enumerate(style_folder_list):\n","  style_images_list = glob.glob(style_folder_list[SF_index] + \"/*\")\n","  style_folder_name = os.path.split(style_folder_list[SF_index]) # horror, ice, dark .etc\n","\n","  style_images_list = natsort.natsorted(style_images_list)\n","\n","  # 스타일 이미지 리스트\n","  for SI_index, SI_value in enumerate(style_images_list):\n","    style_image_name = os.path.split(style_images_list[SI_index]) # horror1, horror2, horror3, .etc\n","    \n","    # 스타일 이미지 선택\n","    style_image, style_shape = load_img(SI_value) # style_content_loss, 전역변수 style_outputs\n","    style_extractor = model_layers(style_layers)\n","    style_outputs = style_extractor(style_image*255) # style_content_loss, StyleContentModel\n","    extractor = StyleContentModel(style_layers, content_layers) # style_content_loss, train_step\n","\n","    # 콘텐트 폴더 리스트\n","    for CF_index, CF_value in enumerate(content_folder_list):\n","\n","      #콘텐트 이미지 리스트\n","      content_images_list = glob.glob(content_folder_list[CF_index] + \"/*\")\n","      content_images_list = natsort.natsorted(content_images_list)\n","\n","      # 스타일 전이\n","      for CI_index, CI_value in enumerate(content_images_list):\n","        location = CI_value\n","\n","        # 저장 경로 생성\n","        asset_folder = os.path.split(content_folder_list[CF_index]) # gobline, zombie, male .etc\n","        asset_name = os.path.split(CI_value)\n","\n","        save_folder_style = styled_location + style_folder_name[1]\n","        save_folder_style_index = save_folder_style + \"/\" + style_image_name[1]\n","        save_folder_style_index_content = save_folder_style_index + \"/\" + asset_folder[1]\n","        \n","        createFolder(save_folder_style) # horror, ice, dark\n","        createFolder(save_folder_style_index) # horror1, horror2, horror3\n","        createFolder(save_folder_style_index_content) # goblin, zombie, male\n","\n","        save_path = save_folder_style_index_content + \"/\"\n","        save_path = save_path + asset_name[1] + f'_{CI_index}_final.png'\n","\n","        # 이미 있는 파일이면 건너뛰기\n","        if os.path.exists(save_path):\n","          continue\n","        else:\n","          origin_image = cv.imread(location, cv.IMREAD_UNCHANGED)\n","          origin_image_shape = origin_image.shape\n","\n","          # style transfer\n","          content_image, content_shape = load_img(location) \n","          img_transformed = get_transformed_img(content_image)\n","          b, g, r = cv.split(img_transformed)\n","          img_transformed = cv.merge([r,g,b])\n","\n","          # model이 반환한 이미지와 사이즈 동일하게 origin image 변환(자동화 완료)\n","          shape = content_shape.numpy()\n","          x, y = shape\n","          origin_image_resized = cv.resize(origin_image, dsize=(y,x))\n","\n","          # alpha channel 추가\n","          final = cv.cvtColor(img_transformed, cv.COLOR_RGB2RGBA)\n","          final[:, :, 3] = origin_image_resized[:,:,3]\n","\n","          # final image 사이즈를 original image 사이즈로 변환\n","          x, y = origin_image_shape[0], origin_image_shape[1]\n","          final = cv.resize(final, dsize=(y,x))\n","\n","          # 저장\n","          cv.imwrite(save_path, final)\n","          cv2_imshow(final)\n","\n","end = time.time()\n","print(\"전체 소요 시간: {:.1f}\".format(end-start))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}